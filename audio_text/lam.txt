Even the packaging. And more, there's challenges coming to reduce costs, intensities, and technologies. As you're looking forward to the next technology notes, you really need to improve what you're doing and also make it manufacturable to meet the customer's specifications. The final challenge across this, I don't want to call it a detox here, but it is extremely challenging and one area specifically in smart manufacturing is a big problem. So if you're trying to improve what you're doing, you need to be able to measure what's happening at the wafer, or the tool, or the forkhead, or the chamber, or the rubber, etc. You need to be able to make a decision on how you're going to bring it together. So some of the specific challenges that's here are the smaller dimensions. I think that's kind of intuitive, right? So you throw these technologies and it becomes much more difficult to measure. Accuracy and measurability and story measuring. That's one of the top things over there. So we need to run out of challenges in a second. Quite interesting. But that is really the beginning of the structure here.

and you're stacking these things so small, it's high to select ratio H that you have. How do you measure what depth you want? If you're 300, 400, 500 layers tall, it's a strange idea. And then from the equipment standpoint, the measurement frequency is pretty interesting because if you'd like to measure every single wave and try to capture as much data as possible, that's half manufactured. You need to get the wavers through the line as fast as possible. So here's a good example. So measurement frequency is a trade-off between how much you're measuring and how much data you're collecting. And then the third or the fourth one right here is hydrometrology. So looking at hydrometrology, you're collecting data at different places, just like Dr. Park was saying, from the equipment, the tools, and measuring the wavers. All of these different sources of the metrology need to be paired together. How do you match things together in the positions that you're looking for? It's not always the same metrology that you're looking at. It's not always the same metrology that you're looking at.

So the next is in the action depth controls, looking at the equipment specifically, how you measure it more accurately and with the technology. Also, how you're making decisions in the action itself. The other thing, points of detection for action, especially, is quite an interesting challenge. If there's no stopping material, if you're really blind, you're not blind, you're actually stopping at a certain depth. But it takes the tool, the control, to decide what time you're going to do it. The ability of those types of samples is quite limited. So if you're trying to do measurements before and after compensation, it's quite difficult to get the exact wavelength of the temperature. A lot of times, you have to wait for it to prosper. So I've posted some more detail here for later in petrology, since we're in petrology. Measuring these things, since we're in situ, is still a little bit difficult to get to the final answer. So when we add it into the tool, it's quite a bit of work.

This is the LSRA component, it's basically shining a wafer on the surface of the boat. It's shining a light on the surface of the wafer occurring in the action. It's reflecting that spectral response on the surface along with the machine, and you can make decisions based off of that. So just measuring it is good, but we employ a machine learning mechanism that has a fast algorithm to make those decisions. So we can create a model that says we can get the spectral response, train it, and then apply it to the potential target test. So it's actually just a machine learning algorithm behind it, and it's active since you touched the monitoring, so it stops it being where it's supposed to be. So the controllability, just with how you fix your controls, you can just orange dot the Z on here, and you can write these specs for decision control. So in the next piece of the data itself, we'll look at the record steps and the pieces that are there, and then how you're looking at the event rates. So in chamber conditions, we actually encourage you to get a simple record using machine learning.

These are tested by a manufacturer over six months of time. And the system A, the example, the 45% reduction in carbon. The other system B was over 50%. Those fantastic process controls are really hard to do since it doesn't consist of a lot of searching every way for carbon reduction. You have to go through it, make decisions early, every single step. To summarize what I just said, bring all these pieces together while making the equipment and the tools smarter, give them more capability. Building and machine learning is a big decision task. The ways to get the system to get more controllability and active controllability are still a big part of making smart manufacturing possible. It obviously opens up new opportunities for A, B, C, D, M, classes of control, platforms, other technologies and tools to integrate this stuff.

So tying it all together, tying it all together, the equipment intelligence department did a good reference that you also need to design the tools and equipment to be smarter in order to enable this kind of interaction. Absolutely true. So as we go through this, my research is looking to make the equipment smarter and bring these pieces together. So not just the equipment, but also the engineers that are interacting with this. We have expert controls, data optimization, initial work optimization, maintenance and variability control, fleet optimization, and prediction. So the whole gamut around the equipment is how do we make it smarter, better, faster. So just focusing in on chamber manufacturing, we have multiple chamber tools that we bring in to high volume manufacturing. One of the challenges that you have is making every single one of these behavioural mechanisms work. A lot of work has been done to make this a little bit faster.

control to get those to the tumbler, inspect, tighten it in. The initial distributions on these are quite large. There's a novel that's part of that, but it's also part of the processing scheme. So you simply make this optimization and bring it to a specific one site or a school for that reviewability. Bring them all to a single data point for the optimization of other files. Then how to bring all of them back into the novel. So this fleet management, bringing this in with all the data you have, it's really important for this part of the production. So doing this actively with all the processes in that novel. It's always changing what you're doing. So looking at the data like this, in terms of fleet management, there's a case over on the left you see here with this is a wafer clean optimization. So after companies have always been making wafers that are in a need-not-to-stand-up-to-risk condition, they're going to be doing that too. Without doing any of these optimizations, just running it, you get quite a large deviation. So just activating the WCO.

There's much more repeatability and performance of the process. And then the second, the variability reduction, so it's tools that are drifting and moving through, looking at the data sets and figuring out what turned out to be the value. WCOs and WCOs, right? Actually, on some of these, one specific test case we found was quite an interesting phenomenon, something that's skewed from kind of the real world of consumer economics. And so that data set is all very similar. But in optimization, they were meant to maintain this as a tool. They started to back off a hell of a process and it was kind of, wasn't quite sure what it was going to do. And so they quickly found it, because they were monitoring it, and they actively funneled it to these crews that produced, that worked back and forth to make sure the right specifications were properly set. And they've made it back now, and they're going to bring it back in. So not only did it help them in the process development, but also in understanding the layout of the consumer system and trying to figure out what the tool would be thinking about.

process where the turbulence is disturbing the image. Even interesting, additional interesting point is when you're making sorter tools and equipment, you have to put more sensors on them. The sensors help track what's happening in the actual adapter, the tool process itself, for every single wafer that runs through it. And it's quite different than a process technology monitor, where you measure the wafer after the edge, and then can give you samples, and have low frequency measurements. I've just sampled some of the wafers before, I've sampled some of the wafers after, and we're doing the same ones. We're making decisions based off of those two pieces. I'm using the tool sensors in Smarter and Vector. You can monitor every single wafer that's happening. We're actually using the tool sensor data to make decisions based off of what's happening. We're using aviation data to make decisions based off of what's happening. So the Smarter tool is only enabling this kind of monitoring, I want to get back to what I was saying earlier. It generates a lot more data, which if you do it, you also make a decision.

and that's part of the story. I think the tools themselves that we're highlighting here as well as the internex equipment and pieces that are coming out, putting more and more sensors on top of it, and it's not just for any reason, it's just really targeted to sensors. We build a lot of equipment and scaling to separate out what's part of the technologies that we're running across the field. Our sensors are being activated and collected more and more in terms of more than the previous generations of these tools as we look forward. With support manufacturing, we have to start at the base of the problem right away because the tooling and equipment itself has to be a lot smarter just to be able to optimize the way that we're doing it. Okay, and I'll wrap up. 23 seconds, perfect. I think the overall challenge for the way that we're manufacturing is quite clear, right? The technologies of the future, even today, are quite small and extremely challenging to manufacture, so if you're trying to go to the next level where it's going to be more challenging, smaller...

technology, smaller sizes, what are most of the processes going to look like? It's more difficult to figure out how to do smart interconnection in this space. We need to plan today in order to kind of enable the future for that kind of interaction. And so from my research, I'm looking at many different aspects of basically creating digital twins across this space, from process integration to tools, equipment, chamber matching across it. It really is a quite interesting place to be. I think the call-to-action at the bottom, I think, is always, we're noting these down. The more talks I listen to, the more it is. But the sharing of the data is really important. As we're going through this, there's a lot of interesting control of who owns the data. Who's going to make decisions? Who knows the idea of what and how to use what data? But the data sharing is one thing that will help enable smart manufacturing. So it's a call to all of you as well to think about how we enable this, how we support it, how we work together as an entire manufacturing organization with the technology that we have. So thank you very much for your time.

Thank you.

So from our perspective, looking at, in this case, starting with the process model, and then versus how we're trying to, how do you mimic what's happening, how do you build that vision? So I'll introduce here the first fabrication platform, maybe some of you have heard of it before, but really it's for process integration and vision development. Looking at the entire process flow, so we start with your silicon, all the way to the end, moving each process step in between. So that's one of the inputs is the process flow, the edges, the depths, the means, the metrologies, all of that, and for those higher steps, we call them master, we call them master, and it's a predictive process flow, so each of the process steps has a little bit of color, and there's a process step that hits it, and casts whatever changes to it. So if there's an overhang, or there's a typography change, the next step will be here. So it's building the visual input for the process integration. Oh, that's great, we have a model we put together, guys, but what do you do after that?

There's a ton of applications that you can start to imagine once you have a model that's representing your integrative flow, start making smart decisions for manufacturing. So specifically with metrology in mind, it's a model, so it has a lot of advantages and to manage the model, metrology is in there. From CV, sub-levels, everything you can measure, it's virtual, you can measure it. There's also things that are not measurable when you're in a classroom or a classroom. It's virtual. It's not descriptive, it's something that you can measure with the technology. You can start to quantify what the changes are. So this metrology adds an additional value on top of just having a model that you can explain to a manufacturer. You can start making decisions with that. So we talked here about the process model calibration. We're looking at building a digital twin for this stuff. And if you have silicon data or you have sequence, you can take the information,

All this, sorry, it's hard for me. In the middle is matching that with what you have in your mind, from cross-pattern image to core calibrations. And there's some machine learning behind that goes through and calibrates the model into the final targets that you're trying to target. So you can actually match up your hardware to still give me some great visual to it in the process world. This is the methodology to build the two together. And then you can apply it to applications like this So how do you build a machine learning that can take that same model and put it in a process model that can be followed up with evolution? I'll use an example case here, on the top. Just think about it as a gate in the center, there's a source drain on either side, there's some space in the material, they have an open area. Kind of like counter-technology. But in general, it's a real factor. But here there's a specific step to open up that specific spacer to pull up the material.

So this simple process integration represents what's happening on the wafer. There's a lot of optimization you can do, even in the virtual world, so if you match like this process test and create a model, there's choices that you can make of the film thicknesses, how much film you want to remove, how much air gap you want to get, and even in the models themselves, you can look at specific stuff when you're doing your depositions. There's a lot of different parameters you can control. But because there's so many process variations, even if you're running just equipment, it takes a lot of iterations to get through, figure out the data, collect it, and make decisions. There's a lot of noise in the deposition. To bring this into the program, it's just a simple tutorial process. You can run a virtual study.

a smaller number of GPUs around us, bring them in and train a T-learning model, and then do the build and predict out the build and then test what we're trying to do. And then run the model to actually count the number of GPUs we need to do the prediction on. So in the case of the floor for the space order goal and optimization, using the digital world that's been trained in the hardware, we do a lot of work here because it's a model where everything is specific to what's supposed to be coming out. And the trial is developed here. You can do a very good prediction that ties you together and bring out the final result on specific hardware. So this specific case, we run it from different cases. Just some of the results that we're getting were phenomenal when we looked at it a few times. Increasing the DOEs that we're trying to run for hardware by 75%. The accuracy of the prediction is close to 100%. So it will never get higher. Even the time scale is a little bit different.

Obviously, a big part of it is how do you get to the technology acquisition part as quickly as possible. And it's quite easy to implement in this kind of process. So it takes some steps and time to build up your infrastructure to be able to support this. You have to have the data curated. You have to be prepared to move forward. And once you have it all together, you can package it up and make decisions for it. So in this case of Metrology, again, I'll talk about supervised image measurement. This happens everywhere. It's the same thing as before. But measuring cross-section, whether it's a percent or a tenth cross-section, a big part of the process engineers come up. You're collecting data. I ran some experiments on some tools. I get the results back. I look at what the cross-section looks like. I have to make some decisions. So how much did something change? The site volume, the CDs, everything else. It's very time-consuming. And a lot of it's manual. So human error. We teach what people have done. I'll see if we can have all the engineering powers. Thank you.

It's slow, so you're actually not hearing some of this. So it's like 40 minutes in some cases for the total image. The amount of clicks per page, the amount of times you click the mouse is like 170% of the time. Which is fantastic. You're wearing it on the mouse. So after analyzing this, and this is a core part of technology development, we approached this with supervised image and control images. So it's our kind of exclusive post-doc technology. And it's a flowchart kind of over here, right? Where we have the input images of this technology itself. With some reduced reduction in the thing. And then we have the three components that we're running into. For computer vision, machine learning, and the deep learning models for how it is. And then we do the test. The test is sitting our computations and measurements out. So we have this software process where we're able to measure these samples much, much faster. So I'll do that, but also have the computer

and through the flow, it has the images, and it's going to increase the number of central surfaces. It gives you the piece, and you can do the measurements of the body. So it's a much, much faster approach. And then the results we had on this, the one was just automated, which is a huge part of it. So instead of hiring more and more engineers to try to get to the timing, the algorithms actually are going to be faster. There are 170,000 clicks per month, and now it's 1,000 clicks per month. So it's huge savings in time. And it's fast. That 40-minute measurement, that's something like 100 tons of sampling, is under a minute using a machine. And I think the more interesting piece that we ended up doing is complete sampling. When engineers go and target a sample of the path, they measure specifically what they're looking for. So for adopting the metrology and machine learning here, you can measure everything on every single sample and collect all the information. Maybe you don't need it today, but the information's always available for those decisions Thank you.

