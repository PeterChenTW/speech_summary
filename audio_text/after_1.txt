I'm very honored to have this session, especially the starting of this session. I'm very proud of Dr. Chih-Yu Lai and his team. We've been here for a long time now. We've been in the fact data analytics. We've been in the process of controlling some of them. So, my area right now, basically, everything here is top-level, everything is, you know. We do logic, URLs, CIS, and many, many other things. So, I'm mostly in charge of the smart manufacturing and the development part. When I'm not working, I'm just using the UI for my computer. You see the picture like this. It happened like a few months ago in Korea. Unfortunately, I'm kind of running out of my business cards. I was not able to hand out during that time.

So this is my contact number. If you have any questions after this session, feel free to ask. Okay, let's get started. Alright, first, goals. What do you want to achieve? So, I believe that many sessions this morning and yesterday's session we talked a lot about our drive to autonomous or AI driven analytics and so on. So, just imagine yourself like 7 years from now to 2030, and maybe since we are in Taiwan in this year. Imagine yourself you are just very fresh, graduating and just joined one of the prestigious companies in Taiwan in TSMC, OEMC and you are a new legend here. So, right now, you have to go through a lot of massive training to be a sponsor or some sort of anything. But in 2030, we may not need that because you are just fresh graduating. You can just, you know, let's say...

Everything's changing right now. So we are looking at, that's just one word, we don't have to talk about different type, different program, different type of infrastructure. And what we need to do is sales provider. This morning, we already talked about this, the difference between before and now. Even Microsoft presents it nicely, but why we don't need labor data anymore? Not exactly, we don't need, we want some sort of agreement even more. Now, instead of all this, we just need transformers. In the near future, we may have a little different, but transformers, nobody can deny that transformers is the leisure point of all this big changes of what we are facing now. And then, we don't need any of this. In the near future, what do you want to know? Not just this forecast area, anything you want to know, you don't have to. So, I just copied the title of this morning session.

We already talked about the details of GenAI, what you can do. In the different aspects, so machine learning and data mining, I mentioned that before we go there, before GenAI actually can handle all these weird kind of data without any human touch, at least for the next couple of years or 3 or 5 years ago, we have to analyze the data so that GenAI can handle it. And the way we do is with different data types, so in a different way. So we used to use rules. So we basically recycle our data. So let's say we go to the cloud. What do we have to do? These SOP or rules you have to follow. When you make a new sensor, you have to follow these many instructions. All this training. So after that, these things, you use neural network. Okay, you can just go similar way. You don't have to exactly follow the way.

is good enough, we can handle it. There's a neural network. But now, as you know, we just use a transformer. We don't need any of this. Does it have at least a proper keyword that is specific to what we want to do? It just put the proper data, and it's a good server. As you can see, I'm kind of repeating almost the same logic over and over again so far. What we'll find is that the data drain goes down with JDNA. And JDNA cannot be done automatically. We have to make it happen by Tomp engineering. In this case, the data is Tomp. And not only just a different type of data, our FAP data is very vibrant. It just doesn't stay still. It can shift, read to, and we have the maintenance and a lot of procedure there. So for example, this is just FTC data. It fluctuates a lot. It's like putting more than 10 times, many, many times.

If you ever look at the NES data, you know NES is one of the most important sensors in the plasma-related human. But we are not using the capability yet because it's so complicated, this three-dimensional or B4-dimensional. We are using only one-dimensional or top-dimensional view. So we have to need to understand how we can utilize this complicated data. And then we use a lot of different algorithms to do it. But again, now, from LGIT, from Samsung's perspective, my team's perspective, we already switched all these algorithms to WURT or GBP, or possibly WURT, for now, because the computing power we need is that we can use WURT instead of GCP. So right now we already have, we are seeing the effect changes about our methodology when it comes to machine learning already. Okay, so in the data analytics, so this is the schematic.

of what we do for the 3D net. Before, it was really difficult to have understandable metrology. Even OCD, or any of x-ray, we cannot find exactly how the 3D net high-res configuration will have. So we did a lot of research, and we find out ways to figure it out. So we just have a lot of different protection, and after that, we run neural network, deploying like this. This time we use ResNet, which is from five years ago, but of course, we are trying to convert it into a transformer, basically. Inspection. Inspection is one of the first items we've been using in 3D net technology, because a lot is related to gravitation, and so on. So we use a lot of this stuff, and this runs our network, deploying, and so on. So I presented this last July at a central event. A couple of things. Non-featured, if you're ever in.

maybe the inspection is here, we don't, like majority of them, we just throw them out because we don't know what they are, it's non-measured, and then if you're able to find like 80% to 10% to 30% reduced, that's non-measured because machine learning can capture and identify what they are. After that, maybe even when spotting, so instead of going to the workforce, scan the whole wafer and review individual feedback. So why do we do that? We just capture, we just dump, we're trying to find a way to the system recognition in the imagined review, and there are a lot, now they're already out there, about the super cell resolution enhancements and so on. Okay, and I already covered OES, so this is one example, OES, it's pretty dangerous, and we are only using two demanders because it's so complicated. With the machine learning, what we have to do, not only the issue of the paper, there's many of the people.

These are kind of overlap each other. So we basically use the rule based, which is we know wave form and the wave levels, which data is related to which wave level. But if you run a lot of the machine learning, you're able to find what is actual data, what is actually linked as a whole. And on top of that, you're able to find exact, correct endpoint without looking through the human environment. And then for trace, I skipped this part, but I think at least they already does. But before, we only focused on what is the statistic of statistic step within this here. But now, we try to use all data set without dissecting any part. So we can basically utilize everything we did. And then here comes the part. So if you look at the kingdom, there are a lot of part inside. We only look at, we used to look at only out of the sensor for human. But there are a lot.

There are a lot of parts that we keep using over and over again. And you will be surprised to know, some parts, they swap between A-chamber, B-chamber, or A-tube and B-tube. And you don't get to check out where it comes from. So, one specific part, if it has never been used from chamber A, never been cleaned and used from chamber B, definitely it will cause some issues. So, now, we are into that level, we have to picture everything required, the history, and then all put together into the machine learning of AI and so on. But again, data is important. Generally, you cannot find any issues. Okay, and then the incubant control part. You know what is edge computing. So, there are cloud and very heavy computing, and there is a computer right next to what you need, and allow devices to control IoT or edge computing. So, from tonight's manufacturing perspective, there is a human and there are a lot of GPUs we have to deal with.

which is a lot. So if you just imagine that, this connection that I think for the human, all the computers, well, it's so complicated to communicate with the human, with one word, as we hope. So we have to add a lot of things in between us and edge computing. And on top of that, these days, DNA has a lot of opportunities to create us. One of them is like my thing, to be utilized on this agent, through the edge computing, we are going to the cloud directly, once we know how to make models. Okay, I'll skip this, without further, I have only two minutes left. So, what is the future? So the next slide, what I'm showing, is the items we can think about, how to make all this data standard. And we already talked about this, in the small e-commerce data. And I guess you know, all the way,

we need to first control all these things in the top of the economy. And, of course, they're not going to react. They are working. One of the examples is we are trying to use this predictive approach. This is basically how humans can be trained to become smarter. And we use this procedure to computer so that we don't give the rule. We just ask the computer to become trained so that humans can learn. Or we have to utilize a lot of text-based data. So right now, I'm trying to make it all LLM. It is possible to do that. But our text-based data, meaning it's like chart, everything is combined. So that has to be understood. And there's a lot of network learning. So network here is more important than network because all the LLMs that you decide to try to establish in Asia, there's no network.

2030, what is written, it's definitely a generated seed, right? So maybe some other technology, but we're going to just type like this way, hey, wafer chat. I just named it wafer chat, or chat, or whatever it is. And can you give me the loadout of those one nanometer of knowledge you're going to accept? I assume that 2030, one nanometer is a kind of legacy knowledge in the future. So I guess you want to have the real issues, and then like anything, performance over the past, ups and downs, you just, instead of you just go through all the weeds we have to clean, wafer is behind. Then you just type this. And then, well, so that will be the result of the whatever issue you have. That's something we'd like to have in the near future. Maybe 2030, maybe you can get a compromise like that. But can that just get you done, just dumping all the data into computers or AI?

actually fits engineering concepts inside. It doesn't object to what data we will see in that equation. It just finds the ways in data. So how we can infuse our knowledge into the machine or algorithm. The one way is to utilize this network analysis. And then, again, standard data, data set. This is something I'm working with Yasemi together. I'm co-leader of the Hinek, Ikeman Data Publication. We try to make all the Hinek, Ikeman sensor, parameter data stand out across all the board. So that's something we have to work together. Oh, one other reason is, if you're really surprised, this is one example. This is version one, two, three by different era. One Hinek, Ikeman, we are utilizing, even in Samsung, we have a lot of resources, the manpower and the computing power. We are utilizing only 20% of what is available. And it's not getting better year by year.

So we have to utilize, and why we cannot, because we don't have the information. So we're trying to make it in the standard industry not just for Amazon. So all these things need to be together. So again, our goal is we don't have to do a thing. We just want to do anything. We just do whatever it means to do it all. We don't need to do all this. Just we need to train your AI. Train is not a simple training like machine learning, like prompting, data engineering, everything in one. So this is what we are doing so far. But as I said in the beginning, I said 2030. Nobody knows we're going to be in 2030. Probably much faster, maybe three years, four years. Hopefully, you can see that. So in the next couple of years, we can say, like on Taiwan, we can actually talk about what we are doing utilizing all this technology. Thank you. Thank you. Thank you.

or JSON data, more specifically. So as you know, you have to have all this data loaded properly, not just loaded in itself. If you just dump everything here in the data lake, it will not give you the answer automatically. In the audience this morning session, one of our speakers said, the importance of the prompt. You cannot just throw away any picture. You have to leave the data properly so you can get the answer as you want. So you have to have this wafer map, all these kinds of analysis, or wafer history, or metrology inspection, all this data. Not only that, from each one side, you need to have here FTC data, not just FTC data. You have to have the feature engineered properly so you can map that into whatever you want to know, or trace analysis, or adding sensors or whatever available. And part of history is there's going to be a lot of maintenance involved.

So, all that, not only does this, what you need to do, has wafer-based data in mind. We are asking issues from wafer that you have to keep track of what happened to that specific wafer. If you tie all this information, if you don't tie all this information into that specific wafer, even though data is there, you cannot just find those codes. Even AI cannot do that. It's not enough. Maybe in the future, they can do it, but at least for now, we cannot do it, or he cannot do it. So, that's the goal that I want to have, and then you, if you were here yesterday, there were a lot of discussion on ESD, and data-driven, how much data would be required, and then that means you have to create a lot of chips, GPUs, CPUs, and so forth, and then current capability and factory capability, and then you can reach that need in a very short period of time.

So that's why we need to have everything doing efficiently, automatically. The leads at this morning are like autonomous, fab, and so on. So, what do you have to do? So, yeah. A couple of months ago, that's the lead who told me he was going to use my slide in his presentation. So I had to tweak my original slide a little bit so that it doesn't look like that. It's saying like this. So basically what it does is, from the, just like autonomous driving, if you want to reach this autonomous fab, which is, you just light up everything, though humans have everything done automatically, you have to go through several levels. I just used the same level in the autonomous driving. I will show you the level in a while. I don't want to go into details because I don't want to explain in very detailed level this morning. So, basically what it is, first, is, before, in its root way, humans decide what needs to be done, whether it's a piece or part of the computer, or it's a rule based on our experience.

or a lot of them. And then we go to data driven, big data. So we just dump a lot of the data set into the system, and hopefully it can find issues, or it can find good control, real good control. Now we are moving to data connected to a self-examiner. The self-examiner may sound a little bit dangerous or scary, but it is what it is. That's what we are all trying to achieve in this journey. OK. And in order to go there, what we have to do, we have to do things in terms of the human side. First, you have to have a lot of people with a vision to it. You need to know exactly what is happening inside or outside the entire effect, which is called visual creativity. And you need to know exactly what is happening. And also, when you make the hardware, you have to have the AI driven design. There's the dimension of this whole aspect. It's so complicated. It's beyond human.

capability. If we haven't reached yet, we will reach soon. So, we have to definitely utilize a lot of capabilities from AI. And this, if you want control, we need to have the sensor, sensing, and analytics control, everything done. But, again, as I said, we have the very well-formatted data so that we can utilize it properly. Okay, so this is the goal we set. Now, we have to go through how we go there, how we are building it up right now. I'll talk about how we plan to do it in the near future. Okay, so, first, there are a lot of work on the centric, the people-centric, small-intervention, and data-centric, or a lot of this in the future. So, a long time ago, I believe, he's not here, but he introduced himself as a AI applicant. But if you are kind of old enough, you know, 60-month life expectancy, like 10 years ago.

16 years ago, one of them I taught it, right? Everybody wants to get a certificate of this record based on this statistics, which is history. And then we had a common sense in engineering and computing. So we built a lot of A, B, C, quantum controller, computing by controller, and so on. So basically, it is so far what it's holding, and then we are trying to change this regime to something else. And that vector is, if you look at closely, before it was a control base, a human base, and then we are using a lot of data, and then we cannot just use this data in itself. So we have to use FPC, or MI, and the diagnostic event. But in the future, what do you need to do? You can just simply feed everything to the data. Are we there yet? No, definitely not. We cannot just dump everything, 300 million attachments in one point only right now. That's just a security reason.

us handle it. We haven't trained it properly yet. So we don't know whether it can be done in the near future. As of now, no. So we have to properly massage our data for them to understand and generate the measure of what we want. Okay, so I made a very simple analysis out of this. First, this is very complicated. This is nothing true in terms of the neural network. Nothing like this, but I cannot give you an estimate. So this red colored box is all about our data in the cloud. We have numeric data, univariate, and hexadecimal data. I mean, it's all sorts of data. And we just feed that into either a supervised or supervised, or a self-based supervised. And then out of the library that we are using, we've been using, and then what we want to know, we want to know about you, or metrology, or reliability, and so on. Since 2017, everything has transformed.

